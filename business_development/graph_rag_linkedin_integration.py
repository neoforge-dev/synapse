#!/usr/bin/env python3
"""
RAG-Powered LinkedIn Content Integration for Epic 5
Intelligent content generation using Graph-RAG knowledge for premium positioning
Integrates advanced graph intelligence with LinkedIn automation for maximum business impact
"""

import asyncio
import json
import logging
import sqlite3
import sys
from datetime import datetime, timedelta
from dataclasses import dataclass
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple

import numpy as np

# Add parent directories to path for imports
sys.path.insert(0, str(Path(__file__).parent.parent))
sys.path.insert(0, str(Path(__file__).parent.parent / 'graph_rag'))

from graph_rag.core.advanced_graph_intelligence import AdvancedGraphIntelligenceEngine
from graph_rag.core.graph_rag_engine import SimpleGraphRAGEngine
from graph_rag.api.dependencies import get_graph_repository, get_vector_store, create_embedding_service
from graph_rag.config import get_settings

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

@dataclass
class RAGContentSuggestion:
    """RAG-powered content suggestion with graph intelligence"""
    suggestion_id: str
    topic: str
    content_angle: str
    target_audience: List[str]
    supporting_entities: List[str]
    relationship_insights: List[str]
    engagement_prediction: float
    viral_potential: float
    business_value_score: float
    knowledge_sources: List[str]
    unique_perspectives: List[str]
    competitive_advantages: List[str]
    optimal_timing: Dict[str, Any]

@dataclass
class IntelligentLinkedInPost:
    """Intelligent LinkedIn post generated using Graph-RAG"""
    post_id: str
    content: str
    hashtags: List[str]
    engagement_hooks: List[str]
    call_to_action: str
    target_audience: List[str]
    supporting_evidence: List[str]
    graph_insights_used: List[str]
    predicted_engagement: float
    business_impact_potential: float
    posting_strategy: Dict[str, Any]

@dataclass
class ContentPersonalization:
    """Personalized content based on audience graph analysis"""
    personalization_id: str
    audience_segment: str
    personalized_angle: str
    relevant_entities: List[str]
    relationship_context: str
    engagement_optimization: Dict[str, Any]
    conversion_probability: float

class GraphRAGLinkedInIntegration:
    """RAG-powered LinkedIn content integration using advanced graph intelligence"""
    
    def __init__(self):
        """Initialize Graph-RAG LinkedIn integration system"""
        self.settings = get_settings()
        self.db_path = "graph_rag_linkedin_integration.db"
        
        # Initialize database
        self._init_database()
        
        # Initialize Graph-RAG components (will be set up properly in production)
        self.graph_intelligence = None
        self.graph_rag_engine = None
        
        # Content generation parameters
        self.content_types = [
            "technical_insights",
            "controversial_takes", 
            "personal_stories",
            "industry_analysis",
            "thought_leadership",
            "case_studies"
        ]
        
        self.audience_segments = [
            "technical_leaders",
            "startup_founders", 
            "enterprise_architects",
            "product_managers",
            "engineering_teams",
            "executives"
        ]
        
        logger.info("Graph-RAG LinkedIn Integration initialized for intelligent content generation")

    def _init_database(self):
        """Initialize SQLite database for content tracking"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # RAG content suggestions table
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS rag_content_suggestions (
                suggestion_id TEXT PRIMARY KEY,
                topic TEXT,
                content_angle TEXT,
                target_audience TEXT,  -- JSON array
                supporting_entities TEXT,  -- JSON array
                relationship_insights TEXT,  -- JSON array
                engagement_prediction REAL,
                viral_potential REAL,
                business_value_score REAL,
                knowledge_sources TEXT,  -- JSON array
                unique_perspectives TEXT,  -- JSON array
                competitive_advantages TEXT,  -- JSON array
                optimal_timing TEXT,  -- JSON object
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                status TEXT DEFAULT 'generated'
            )
        ''')
        
        # Intelligent LinkedIn posts table
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS intelligent_linkedin_posts (
                post_id TEXT PRIMARY KEY,
                content TEXT,
                hashtags TEXT,  -- JSON array
                engagement_hooks TEXT,  -- JSON array
                call_to_action TEXT,
                target_audience TEXT,  -- JSON array
                supporting_evidence TEXT,  -- JSON array
                graph_insights_used TEXT,  -- JSON array
                predicted_engagement REAL,
                business_impact_potential REAL,
                posting_strategy TEXT,  -- JSON object
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                posted_at TIMESTAMP,
                actual_engagement REAL,
                performance_analysis TEXT
            )
        ''')
        
        # Content personalization table
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS content_personalization (
                personalization_id TEXT PRIMARY KEY,
                audience_segment TEXT,
                personalized_angle TEXT,
                relevant_entities TEXT,  -- JSON array
                relationship_context TEXT,
                engagement_optimization TEXT,  -- JSON object
                conversion_probability REAL,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                effectiveness_score REAL
            )
        ''')
        
        # Graph insights cache table
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS graph_insights_cache (
                cache_key TEXT PRIMARY KEY,
                insight_type TEXT,
                insight_data TEXT,  -- JSON object
                business_relevance REAL,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                expires_at TIMESTAMP
            )
        ''')
        
        conn.commit()
        conn.close()
        logger.info("Database initialized for Graph-RAG LinkedIn integration")

    async def generate_rag_content_suggestions(self, 
                                             query_context: str = None,
                                             target_audience: List[str] = None,
                                             content_type: str = None) -> List[RAGContentSuggestion]:
        """
        Generate intelligent content suggestions using Graph-RAG analysis
        
        Leverages knowledge graph relationships and vector search to identify
        high-value content opportunities with business impact prediction.
        """
        logger.info("Generating RAG-powered content suggestions using graph intelligence")
        
        try:
            suggestions = []
            
            # If graph intelligence is available, use advanced analysis
            if self.graph_intelligence:
                # Get community insights for content topics
                communities = await self.graph_intelligence.detect_graph_communities(min_size=3, max_communities=15)
                
                # Generate content recommendations
                recommendations = await self.graph_intelligence.generate_content_recommendations(
                    target_topics=None,
                    audience_segments=target_audience or self.audience_segments
                )
                
                # Identify content gaps for unique positioning
                gap_insights = await self.graph_intelligence.identify_content_gaps()
                
                # Analyze temporal patterns for trending topics
                temporal_insights = await self.graph_intelligence.analyze_temporal_patterns(time_window_days=30)
                
                # Convert recommendations to structured suggestions
                for rec in recommendations:
                    suggestion = RAGContentSuggestion(
                        suggestion_id=rec.recommendation_id,
                        topic=rec.topic,
                        content_angle=rec.content_angle,
                        target_audience=rec.target_audience,
                        supporting_entities=rec.supporting_entities,
                        relationship_insights=self._extract_relationship_insights(rec.relationship_patterns),
                        engagement_prediction=rec.engagement_prediction,
                        viral_potential=min(rec.engagement_prediction * 1.2, 1.0),
                        business_value_score=rec.business_value_score,
                        knowledge_sources=self._identify_knowledge_sources(rec.supporting_entities),
                        unique_perspectives=rec.competitive_advantage,
                        competitive_advantages=rec.competitive_advantage,
                        optimal_timing=self._determine_optimal_timing(rec.topic)
                    )
                    suggestions.append(suggestion)
                
                # Add gap-based suggestions for unique positioning
                for gap in gap_insights[:3]:  # Top 3 gap opportunities
                    gap_suggestion = RAGContentSuggestion(
                        suggestion_id=gap.insight_id,
                        topic=gap.description,
                        content_angle="First-mover advantage in underexplored domain",
                        target_audience=["technical_leaders", "thought_leaders"],
                        supporting_entities=gap.entities_involved,
                        relationship_insights=[gap.business_impact],
                        engagement_prediction=0.75,  # High due to uniqueness
                        viral_potential=0.85,  # High viral potential for unique content
                        business_value_score=gap.projected_value / 1000,  # Normalize
                        knowledge_sources=["graph_analysis", "content_gap_identification"],
                        unique_perspectives=gap.actionable_recommendations,
                        competitive_advantages=["First to market", "Unique positioning"],
                        optimal_timing={"immediate": True, "reasoning": "capitalize on gap"}
                    )
                    suggestions.append(gap_suggestion)
            
            else:
                # Fallback to rule-based suggestions without graph intelligence
                suggestions = self._generate_fallback_suggestions(query_context, target_audience, content_type)
            
            # Store suggestions in database
            self._store_content_suggestions(suggestions)
            
            # Sort by business value score
            suggestions.sort(key=lambda x: x.business_value_score, reverse=True)
            
            logger.info(f"Generated {len(suggestions)} RAG-powered content suggestions")
            return suggestions[:10]  # Return top 10
            
        except Exception as e:
            logger.error(f"Error generating RAG content suggestions: {e}")
            return self._generate_fallback_suggestions(query_context, target_audience, content_type)

    async def generate_intelligent_linkedin_posts(self, 
                                                content_suggestions: List[RAGContentSuggestion],
                                                count: int = 5) -> List[IntelligentLinkedInPost]:
        """
        Generate intelligent LinkedIn posts based on RAG content suggestions
        
        Creates engaging, fact-checked posts with supporting evidence from the knowledge graph.
        """
        logger.info(f"Generating {count} intelligent LinkedIn posts using Graph-RAG insights")
        
        try:
            posts = []
            
            for i, suggestion in enumerate(content_suggestions[:count]):
                # Use Graph-RAG engine to generate content if available
                if self.graph_rag_engine:
                    # Query the knowledge graph for supporting information
                    query = f"Create engaging LinkedIn content about {suggestion.topic} focusing on {suggestion.content_angle}"
                    
                    try:
                        # Get knowledge-backed content from Graph-RAG
                        rag_result = await self.graph_rag_engine.query(
                            query_text=query,
                            config={
                                "k": 5,
                                "search_type": "hybrid",
                                "include_graph": True,
                                "style": "engaging"
                            }
                        )
                        
                        # Extract supporting evidence from retrieved chunks
                        supporting_evidence = self._extract_supporting_evidence(rag_result.relevant_chunks)
                        
                        # Generate content based on RAG insights
                        content = self._create_engaging_content(suggestion, rag_result.answer, supporting_evidence)
                        
                    except Exception as e:
                        logger.warning(f"Graph-RAG query failed, using fallback content generation: {e}")
                        content = self._create_fallback_content(suggestion)
                        supporting_evidence = suggestion.knowledge_sources
                else:
                    content = self._create_fallback_content(suggestion)
                    supporting_evidence = suggestion.knowledge_sources
                
                # Generate post components
                post = IntelligentLinkedInPost(
                    post_id=f"rag_post_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{i+1}",
                    content=content,
                    hashtags=self._generate_smart_hashtags(suggestion),
                    engagement_hooks=self._create_engagement_hooks(suggestion),
                    call_to_action=self._create_intelligent_cta(suggestion),
                    target_audience=suggestion.target_audience,
                    supporting_evidence=supporting_evidence,
                    graph_insights_used=suggestion.relationship_insights,
                    predicted_engagement=suggestion.engagement_prediction,
                    business_impact_potential=suggestion.business_value_score,
                    posting_strategy=self._create_posting_strategy(suggestion)
                )
                
                posts.append(post)
            
            # Store posts in database
            self._store_intelligent_posts(posts)
            
            logger.info(f"Generated {len(posts)} intelligent LinkedIn posts with Graph-RAG backing")
            return posts
            
        except Exception as e:
            logger.error(f"Error generating intelligent LinkedIn posts: {e}")
            return []

    async def personalize_content_for_audience(self, 
                                             post: IntelligentLinkedInPost,
                                             audience_segments: List[str]) -> List[ContentPersonalization]:
        """
        Personalize content for different audience segments using graph analysis
        
        Leverages relationship context to tailor messaging for maximum relevance.
        """
        logger.info(f"Personalizing content for {len(audience_segments)} audience segments")
        
        personalizations = []
        
        try:
            for segment in audience_segments:
                # If graph intelligence available, use relationship analysis
                if self.graph_intelligence:
                    # Get entities relevant to this audience segment
                    segment_entities = await self._get_audience_relevant_entities(segment)
                    
                    # Analyze relationships between content and audience
                    relationship_context = await self._analyze_audience_relationships(
                        post.supporting_evidence, segment_entities
                    )
                else:
                    segment_entities = self._get_fallback_audience_entities(segment)
                    relationship_context = f"Content relevant to {segment} audience"
                
                # Create personalized version
                personalization = ContentPersonalization(
                    personalization_id=f"{post.post_id}_{segment}",
                    audience_segment=segment,
                    personalized_angle=self._create_personalized_angle(post.content, segment),
                    relevant_entities=segment_entities,
                    relationship_context=relationship_context,
                    engagement_optimization=self._optimize_for_segment(segment),
                    conversion_probability=self._calculate_conversion_probability(post, segment)
                )
                
                personalizations.append(personalization)
            
            # Store personalizations
            self._store_personalizations(personalizations)
            
            logger.info(f"Created {len(personalizations)} content personalizations")
            return personalizations
            
        except Exception as e:
            logger.error(f"Error personalizing content: {e}")
            return []

    async def fact_check_content(self, content: str) -> Dict[str, Any]:
        """
        Fact-check content using Graph-RAG knowledge validation
        
        Verifies claims against knowledge graph relationships and source credibility.
        """
        logger.info("Fact-checking content using Graph-RAG validation")
        
        try:
            if self.graph_rag_engine:
                # Extract claims from content
                claims = self._extract_claims(content)
                
                fact_check_results = []
                for claim in claims:
                    # Query knowledge graph for verification
                    verification_query = f"Verify the accuracy of: {claim}"
                    
                    result = await self.graph_rag_engine.query(
                        query_text=verification_query,
                        config={
                            "k": 3,
                            "search_type": "hybrid",
                            "include_graph": True
                        }
                    )
                    
                    # Analyze confidence and supporting evidence
                    fact_check_results.append({
                        "claim": claim,
                        "verification": result.answer,
                        "confidence": self._calculate_claim_confidence(result),
                        "supporting_sources": len(result.relevant_chunks),
                        "graph_support": bool(result.graph_context)
                    })
                
                return {
                    "overall_accuracy": np.mean([r["confidence"] for r in fact_check_results]),
                    "claim_results": fact_check_results,
                    "recommendation": self._get_fact_check_recommendation(fact_check_results)
                }
            else:
                return {
                    "overall_accuracy": 0.8,  # Fallback score
                    "claim_results": [],
                    "recommendation": "Manual fact-checking recommended"
                }
                
        except Exception as e:
            logger.error(f"Error fact-checking content: {e}")
            return {"overall_accuracy": 0.5, "error": str(e)}

    def _extract_relationship_insights(self, relationship_patterns: List[Tuple[str, str, str]]) -> List[str]:
        """Extract readable insights from relationship patterns"""
        insights = []
        for source, relation, target in relationship_patterns:
            insights.append(f"{source} {relation} {target}")
        return insights

    def _identify_knowledge_sources(self, entities: List[str]) -> List[str]:
        """Identify knowledge sources for entities"""
        return [f"Graph analysis of {entity}" for entity in entities]

    def _determine_optimal_timing(self, topic: str) -> Dict[str, Any]:
        """Determine optimal timing for content posting"""
        # Simplified timing optimization
        return {
            "day_of_week": "Tuesday",
            "time": "06:30",
            "timezone": "EST",
            "reasoning": f"Peak engagement for {topic} content"
        }

    def _generate_fallback_suggestions(self, query_context: str, target_audience: List[str], content_type: str) -> List[RAGContentSuggestion]:
        """Generate fallback suggestions without graph intelligence"""
        fallback_topics = [
            "AI-Powered Development Trends",
            "Enterprise Architecture Best Practices", 
            "Startup Scaling Challenges",
            "Technical Leadership Insights",
            "Product Management Innovation"
        ]
        
        suggestions = []
        for i, topic in enumerate(fallback_topics):
            suggestion = RAGContentSuggestion(
                suggestion_id=f"fallback_{i+1}",
                topic=topic,
                content_angle="Expert analysis and insights",
                target_audience=target_audience or ["technical_leaders"],
                supporting_entities=[topic.replace(" ", "_").lower()],
                relationship_insights=[f"Industry trends around {topic}"],
                engagement_prediction=0.65,
                viral_potential=0.70,
                business_value_score=50.0,
                knowledge_sources=["Industry expertise"],
                unique_perspectives=["Expert analysis"],
                competitive_advantages=["Thought leadership"],
                optimal_timing={"immediate": True}
            )
            suggestions.append(suggestion)
        
        return suggestions

    def _store_content_suggestions(self, suggestions: List[RAGContentSuggestion]):
        """Store content suggestions in database"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        for suggestion in suggestions:
            cursor.execute('''
                INSERT OR REPLACE INTO rag_content_suggestions (
                    suggestion_id, topic, content_angle, target_audience,
                    supporting_entities, relationship_insights, engagement_prediction,
                    viral_potential, business_value_score, knowledge_sources,
                    unique_perspectives, competitive_advantages, optimal_timing
                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                suggestion.suggestion_id, suggestion.topic, suggestion.content_angle,
                json.dumps(suggestion.target_audience), json.dumps(suggestion.supporting_entities),
                json.dumps(suggestion.relationship_insights), suggestion.engagement_prediction,
                suggestion.viral_potential, suggestion.business_value_score,
                json.dumps(suggestion.knowledge_sources), json.dumps(suggestion.unique_perspectives),
                json.dumps(suggestion.competitive_advantages), json.dumps(suggestion.optimal_timing)
            ))
        
        conn.commit()
        conn.close()

    def _extract_supporting_evidence(self, chunks) -> List[str]:
        """Extract supporting evidence from retrieved chunks"""
        evidence = []
        for chunk in chunks:
            if hasattr(chunk, 'text'):
                # Extract key facts or statements
                evidence.append(chunk.text[:200] + "..." if len(chunk.text) > 200 else chunk.text)
        return evidence[:3]  # Top 3 pieces of evidence

    def _create_engaging_content(self, suggestion: RAGContentSuggestion, rag_answer: str, evidence: List[str]) -> str:
        """Create engaging LinkedIn content from RAG insights"""
        # Create compelling content structure
        hook = self._create_content_hook(suggestion.topic)
        main_content = self._distill_main_insights(rag_answer, suggestion.content_angle)
        value_proposition = self._create_value_proposition(suggestion)
        
        content = f"{hook}\n\n{main_content}\n\n{value_proposition}"
        
        # Keep within LinkedIn limits (3000 characters)
        if len(content) > 2800:
            content = content[:2800] + "..."
        
        return content

    def _create_fallback_content(self, suggestion: RAGContentSuggestion) -> str:
        """Create fallback content without RAG engine"""
        return f"""ðŸš€ {suggestion.topic}

{suggestion.content_angle}

Here's what I've learned from analyzing industry trends:

â€¢ Key insight about {suggestion.supporting_entities[0] if suggestion.supporting_entities else 'the topic'}
â€¢ Strategic implications for {', '.join(suggestion.target_audience)}
â€¢ Actionable takeaways for implementation

What's your experience with {suggestion.topic}? Share your thoughts below! ðŸ‘‡"""

    def _create_content_hook(self, topic: str) -> str:
        """Create engaging opening hook"""
        hooks = [
            f"ðŸ”¥ Hot take on {topic}:",
            f"ðŸ’¡ Most teams get {topic} wrong. Here's why:",
            f"ðŸš€ The future of {topic} is here, and it's not what you think:",
            f"âš¡ 3 lessons I learned from {topic} failures:"
        ]
        import random
        return random.choice(hooks)

    def _distill_main_insights(self, rag_answer: str, angle: str) -> str:
        """Distill main insights from RAG answer"""
        # Simplified content extraction
        sentences = rag_answer.split('. ')[:3]  # Take first 3 sentences
        return '. '.join(sentences) + '.'

    def _create_value_proposition(self, suggestion: RAGContentSuggestion) -> str:
        """Create value proposition for the audience"""
        return f"This matters because it directly impacts {', '.join(suggestion.target_audience)} who are looking to {suggestion.unique_perspectives[0] if suggestion.unique_perspectives else 'drive innovation'}."

    def _generate_smart_hashtags(self, suggestion: RAGContentSuggestion) -> List[str]:
        """Generate smart hashtags based on content analysis"""
        base_tags = ["#TechLeadership", "#Innovation", "#StartupLife"]
        
        # Add topic-specific tags
        topic_words = suggestion.topic.split()
        topic_tags = [f"#{word}" for word in topic_words if len(word) > 3]
        
        # Add audience-specific tags
        audience_tags = [f"#{audience.replace('_', '').title()}" for audience in suggestion.target_audience]
        
        all_tags = base_tags + topic_tags + audience_tags
        return list(set(all_tags))[:10]  # Max 10 hashtags

    def _create_engagement_hooks(self, suggestion: RAGContentSuggestion) -> List[str]:
        """Create engagement hooks for the post"""
        return [
            "What's your experience with this?",
            "Agree or disagree? Share your thoughts below!",
            f"How do you handle {suggestion.topic} in your organization?",
            "What would you add to this list?"
        ]

    def _create_intelligent_cta(self, suggestion: RAGContentSuggestion) -> str:
        """Create intelligent call-to-action"""
        ctas = [
            "Let's discuss how this applies to your business - DM me!",
            f"Need help with {suggestion.topic}? I offer strategic consultations.",
            "Share this with someone who needs to see it!",
            "Follow for more insights on technical leadership!"
        ]
        import random
        return random.choice(ctas)

    def _create_posting_strategy(self, suggestion: RAGContentSuggestion) -> Dict[str, Any]:
        """Create posting strategy based on content analysis"""
        return {
            "optimal_time": suggestion.optimal_timing,
            "expected_engagement": suggestion.engagement_prediction,
            "target_reach": int(suggestion.business_value_score * 100),
            "follow_up_strategy": "Monitor for 48 hours, engage with comments",
            "success_metrics": ["likes", "comments", "shares", "DMs"]
        }

    def _store_intelligent_posts(self, posts: List[IntelligentLinkedInPost]):
        """Store intelligent posts in database"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        for post in posts:
            cursor.execute('''
                INSERT OR REPLACE INTO intelligent_linkedin_posts (
                    post_id, content, hashtags, engagement_hooks, call_to_action,
                    target_audience, supporting_evidence, graph_insights_used,
                    predicted_engagement, business_impact_potential, posting_strategy
                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                post.post_id, post.content, json.dumps(post.hashtags),
                json.dumps(post.engagement_hooks), post.call_to_action,
                json.dumps(post.target_audience), json.dumps(post.supporting_evidence),
                json.dumps(post.graph_insights_used), post.predicted_engagement,
                post.business_impact_potential, json.dumps(post.posting_strategy)
            ))
        
        conn.commit()
        conn.close()

    async def _get_audience_relevant_entities(self, segment: str) -> List[str]:
        """Get entities relevant to audience segment"""
        # Placeholder implementation
        segment_entities = {
            "technical_leaders": ["AI", "Architecture", "Leadership"],
            "startup_founders": ["Fundraising", "Product Market Fit", "Scaling"],
            "enterprise_architects": ["Enterprise Architecture", "Digital Transformation", "Cloud"],
            "product_managers": ["Product Strategy", "User Experience", "Analytics"],
            "engineering_teams": ["Development", "DevOps", "Code Quality"],
            "executives": ["Strategy", "ROI", "Digital Innovation"]
        }
        return segment_entities.get(segment, ["Technology", "Business"])

    async def _analyze_audience_relationships(self, evidence: List[str], entities: List[str]) -> str:
        """Analyze relationships between content evidence and audience entities"""
        return f"Content relates to {', '.join(entities)} which are key interests for this audience segment"

    def _get_fallback_audience_entities(self, segment: str) -> List[str]:
        """Fallback audience entities when graph intelligence unavailable"""
        return await self._get_audience_relevant_entities(segment)

    def _create_personalized_angle(self, content: str, segment: str) -> str:
        """Create personalized angle for audience segment"""
        angles = {
            "technical_leaders": "Focus on implementation and team leadership aspects",
            "startup_founders": "Emphasize growth, scaling, and competitive advantage",
            "enterprise_architects": "Highlight enterprise-scale implications and governance",
            "product_managers": "Connect to user value and business metrics",
            "engineering_teams": "Detail technical implementation and best practices",
            "executives": "Frame in terms of business impact and strategic value"
        }
        return angles.get(segment, "General professional relevance")

    def _optimize_for_segment(self, segment: str) -> Dict[str, Any]:
        """Optimize engagement for specific audience segment"""
        return {
            "tone": "professional" if "executives" in segment else "conversational",
            "technical_depth": "high" if "engineering" in segment else "medium",
            "business_focus": "high" if any(x in segment for x in ["executives", "founders"]) else "medium"
        }

    def _calculate_conversion_probability(self, post: IntelligentLinkedInPost, segment: str) -> float:
        """Calculate conversion probability for audience segment"""
        base_probability = post.business_impact_potential / 100
        
        # Adjust based on segment alignment
        segment_multipliers = {
            "technical_leaders": 0.8,
            "startup_founders": 0.9,
            "enterprise_architects": 0.7,
            "product_managers": 0.8,
            "engineering_teams": 0.6,
            "executives": 0.9
        }
        
        multiplier = segment_multipliers.get(segment, 0.7)
        return min(base_probability * multiplier, 1.0)

    def _store_personalizations(self, personalizations: List[ContentPersonalization]):
        """Store content personalizations in database"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        for p in personalizations:
            cursor.execute('''
                INSERT OR REPLACE INTO content_personalization (
                    personalization_id, audience_segment, personalized_angle,
                    relevant_entities, relationship_context, engagement_optimization,
                    conversion_probability
                ) VALUES (?, ?, ?, ?, ?, ?, ?)
            ''', (
                p.personalization_id, p.audience_segment, p.personalized_angle,
                json.dumps(p.relevant_entities), p.relationship_context,
                json.dumps(p.engagement_optimization), p.conversion_probability
            ))
        
        conn.commit()
        conn.close()

    def _extract_claims(self, content: str) -> List[str]:
        """Extract factual claims from content"""
        # Simplified claim extraction
        sentences = content.split('.')
        claims = [s.strip() for s in sentences if s.strip() and not s.startswith(('What', 'How', '?'))]
        return claims[:3]  # Top 3 claims

    def _calculate_claim_confidence(self, result) -> float:
        """Calculate confidence score for claim verification"""
        confidence = 0.7  # Base confidence
        
        if result.relevant_chunks:
            confidence += len(result.relevant_chunks) * 0.05
        
        if result.graph_context:
            confidence += 0.1
        
        return min(confidence, 0.95)

    def _get_fact_check_recommendation(self, results: List[Dict]) -> str:
        """Get fact-checking recommendation based on results"""
        avg_confidence = np.mean([r["confidence"] for r in results]) if results else 0.5
        
        if avg_confidence > 0.8:
            return "Content appears factually sound with good supporting evidence"
        elif avg_confidence > 0.6:
            return "Content is reasonably supported but consider additional verification"
        else:
            return "Content requires significant fact-checking before publication"

async def main():
    """Main function for testing Graph-RAG LinkedIn integration"""
    integration = GraphRAGLinkedInIntegration()
    
    # Test content generation
    suggestions = await integration.generate_rag_content_suggestions(
        query_context="AI-powered development trends",
        target_audience=["technical_leaders", "startup_founders"]
    )
    
    print(f"\nGenerated {len(suggestions)} content suggestions:")
    for i, suggestion in enumerate(suggestions, 1):
        print(f"\n{i}. {suggestion.topic}")
        print(f"   Angle: {suggestion.content_angle}")
        print(f"   Engagement: {suggestion.engagement_prediction:.1%}")
        print(f"   Business Value: ${suggestion.business_value_score:.0f}")
    
    # Generate intelligent posts
    if suggestions:
        posts = await integration.generate_intelligent_linkedin_posts(suggestions, count=3)
        print(f"\nGenerated {len(posts)} intelligent LinkedIn posts:")
        for i, post in enumerate(posts, 1):
            print(f"\n--- Post {i} ---")
            print(post.content[:200] + "...")
            print(f"Hashtags: {', '.join(post.hashtags[:5])}")
            print(f"Predicted Engagement: {post.predicted_engagement:.1%}")

if __name__ == "__main__":
    asyncio.run(main())